## MAB

![Image](https://multithreaded.stitchfix.com/assets/posts/2020-08-05-bandits/multi_armed_bandit.png)
Multi-armed Bandit set of alogrithms written in Python. The source code can be found on [github](https://github.com/alexeybutyrev/mab).

### List of MAB implementations


- EpsionGreedy
- BetaTS
- Softmax
- UCB1
- AnnealingSoftmax
- AnnealingEpsionGreedy
- AB testing
- Random Select

Also, the package has trial simulations:

- Motecarlo Simulation

with different types of rewards

- Bernoulli Arms (binary rewards)
- Uniform Arms   (uniformly distributed rewards)

## How to Install
Two ways to install

```markdown
- Clone this repository
- pip install mab-hakuinadvisors
```

## How to Use

The best usage example can be found in the file `simulation.ipynb`

The package can be used as
- A part of another library or software
- API (in progress)
- Theoretical learning by using simulations like in `simulation.ipynb` or with different types of rewards, algorythms and simulation parameters

## Documentation
The full documentation of the library and its functionality can be found [here](https://mab.readthedocs.io/en/latest/). Note the documentation is not compleated.


### Authors

If you have any questions email to [Alexey Butyrev](butirev@gmail.com), [Drew Maniglia](drew@hakuinadvisors.com)
